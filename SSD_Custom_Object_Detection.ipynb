{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSD_Custom_Object_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayan0506/SSD-Custom-Object-Detection-Using-Pytorch/blob/main/SSD_Custom_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQCnMOU9pK-l"
      },
      "source": [
        "# **Implement SSD for Object Detection using Pytorch**\n",
        "\n",
        "Here, in this notebook we will try to implement SSD(Single Shot multi-box Detection) algorithm for object detection, this code is inspired from the book - \"[Modern Computer Vision with PyTorch](https://www.packtpub.com/product/modern-computer-vision-with-pytorch/9781839213472)\". FOr this experiment, we will try to utilize the object detection from image size 300, thus we will use SSD300 variant of the SSD series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGmOxRTfumjD"
      },
      "source": [
        "## **Install Dependencies**\n",
        "\n",
        "* [torch_snippets](https://github.com/sizhky/torch_snippets) - contains the utility functions for simple supporting tasks regardinfg tor ch implementations\n",
        "* [How to run wget quietly](http://oliviertech.com/linux/how-to-run-wget-quietly/#:~:text=The%20wget%20command%20is%20used,are%20writtent%20in%20the%20output.) - wget function is used to download files from given url, and \"wget -q\", here -q parameter helps to download from wget quietly, so that the output/download status will not print in the console/terminal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9Doaoz7crli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b06f1b6-b73e-44ab-a5f5-879d42e2c35d"
      },
      "source": [
        "# installs torch_snippets and utils quietly\n",
        "!pip install -q torch_snippets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███████▋                        | 10 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 20 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 30 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 867 kB/s \n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 33.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 39.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQWJLU272fG2"
      },
      "source": [
        "## **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49ttx0-Mz0Fl"
      },
      "source": [
        "import os, collections\n",
        "from torch_snippets import *\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4a2OT75dFDj"
      },
      "source": [
        "#### **Environment setup**\n",
        "\n",
        "Checks whether the torch uses the gpu or not, and the currrent device assign and checks device properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VySkv50cdIkM",
        "outputId": "db4b6f1d-5a17-4ebb-b962-671073f2ad2f"
      },
      "source": [
        "# asign device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "#print(f'Available devices {torch.cuda.get_}')\n",
        "# torch.cuda.current_device() returns device id of the current device from available list\n",
        "# torch.cuda.get_device_name(id) returns the device name corresponding to the id\n",
        "print(f'Current device - {torch.cuda.get_device_properties(torch.cuda.current_device())}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current device - _CudaDeviceProperties(name='Tesla K80', major=3, minor=7, total_memory=11441MB, multi_processor_count=13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIiCNuVx2_f9"
      },
      "source": [
        "## **Data Download**\n",
        "\n",
        "* Download the bus-truck images dataset for object detection from dropbox link.\n",
        "* Clone ssd utils - [SSD-utils](https://github.com/sizhky/ssd-utils/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUSY3kU32uEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f5a9186-9769-40a7-c9c6-83b2e8b913c4"
      },
      "source": [
        "# project folder\n",
        "project_path = 'open-images-bus-trucks'\n",
        "\n",
        "# checks whether the data is downloaded or not \n",
        "if not os.path.exists(project_path):\n",
        "  # download the tar.xz zip file from dropbox\n",
        "  !wget --quiet https://www.dropbox.com/s/agmzwk95v96ihic/\\\n",
        "open-images-bus-trucks.tar.xz\n",
        "  # extract the tar file\n",
        "  !tar -xf open-images-bus-trucks.tar.xz\n",
        "  # remove the zip file to  save space\n",
        "  !rm open-images-bus-trucks.tar.xz\n",
        "  # clone the SSD utils repo\n",
        "  !git clone https://github.com/sizhky/ssd-utils/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ssd-utils'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ephk8JbCqMx_"
      },
      "source": [
        "## **Data Preperation**\n",
        "\n",
        "Data investigation is done here, create dataframes and check the available images and annotation files|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97almhRvvZsU"
      },
      "source": [
        "# define data folder paths\n",
        "data_root = os.path.join('/content/', project_path)\n",
        "image_root = os.path.join(data_root, 'images')\n",
        "\n",
        "# load the csv file containing data info in a pandas dataframe\n",
        "# raw dataframe\n",
        "df_raw = pd.read_csv(os.path.join(data_root, 'df.csv'))\n",
        "# copy the dataset\n",
        "df = df_raw.copy()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OjdDJx0vKVQ"
      },
      "source": [
        "**Checking duplicate samples**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "E5Ckt2lOs5qY",
        "outputId": "a3eb3dc4-0b4b-4b3e-f7b4-bf124dc51b48"
      },
      "source": [
        "# checking the duplicate imageid\n",
        "df_d = df[df.duplicated('ImageID')]\n",
        "df_d"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageID</th>\n",
              "      <th>Source</th>\n",
              "      <th>LabelName</th>\n",
              "      <th>Confidence</th>\n",
              "      <th>XMin</th>\n",
              "      <th>XMax</th>\n",
              "      <th>YMin</th>\n",
              "      <th>YMax</th>\n",
              "      <th>IsOccluded</th>\n",
              "      <th>IsTruncated</th>\n",
              "      <th>IsGroupOf</th>\n",
              "      <th>IsDepiction</th>\n",
              "      <th>IsInside</th>\n",
              "      <th>XClick1X</th>\n",
              "      <th>XClick2X</th>\n",
              "      <th>XClick3X</th>\n",
              "      <th>XClick4X</th>\n",
              "      <th>XClick1Y</th>\n",
              "      <th>XClick2Y</th>\n",
              "      <th>XClick3Y</th>\n",
              "      <th>XClick4Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00006bdb1eb5cd74</td>\n",
              "      <td>xclick</td>\n",
              "      <td>Truck</td>\n",
              "      <td>1</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.999167</td>\n",
              "      <td>0.204261</td>\n",
              "      <td>0.409774</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.849167</td>\n",
              "      <td>0.702500</td>\n",
              "      <td>0.906667</td>\n",
              "      <td>0.999167</td>\n",
              "      <td>0.204261</td>\n",
              "      <td>0.398496</td>\n",
              "      <td>0.409774</td>\n",
              "      <td>0.295739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0004d5a9dd44ab6a</td>\n",
              "      <td>xclick</td>\n",
              "      <td>Truck</td>\n",
              "      <td>1</td>\n",
              "      <td>0.094375</td>\n",
              "      <td>0.897500</td>\n",
              "      <td>0.147014</td>\n",
              "      <td>0.934150</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.365000</td>\n",
              "      <td>0.094375</td>\n",
              "      <td>0.333750</td>\n",
              "      <td>0.897500</td>\n",
              "      <td>0.147014</td>\n",
              "      <td>0.609495</td>\n",
              "      <td>0.934150</td>\n",
              "      <td>0.822358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0004d5a9dd44ab6a</td>\n",
              "      <td>xclick</td>\n",
              "      <td>Truck</td>\n",
              "      <td>1</td>\n",
              "      <td>0.860625</td>\n",
              "      <td>0.999375</td>\n",
              "      <td>0.249617</td>\n",
              "      <td>0.390505</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.992500</td>\n",
              "      <td>0.999375</td>\n",
              "      <td>0.860625</td>\n",
              "      <td>0.921250</td>\n",
              "      <td>0.249617</td>\n",
              "      <td>0.294028</td>\n",
              "      <td>0.325421</td>\n",
              "      <td>0.390505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0007eeeabf3c5e5c</td>\n",
              "      <td>xclick</td>\n",
              "      <td>Bus</td>\n",
              "      <td>1</td>\n",
              "      <td>0.620625</td>\n",
              "      <td>0.999375</td>\n",
              "      <td>0.406667</td>\n",
              "      <td>0.647778</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.999375</td>\n",
              "      <td>0.871875</td>\n",
              "      <td>0.620625</td>\n",
              "      <td>0.406667</td>\n",
              "      <td>0.458889</td>\n",
              "      <td>0.647778</td>\n",
              "      <td>0.432222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>000924a411c24d25</td>\n",
              "      <td>xclick</td>\n",
              "      <td>Bus</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086875</td>\n",
              "      <td>0.429644</td>\n",
              "      <td>0.702627</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.033125</td>\n",
              "      <td>0.086875</td>\n",
              "      <td>0.008750</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.429644</td>\n",
              "      <td>0.632270</td>\n",
              "      <td>0.702627</td>\n",
              "      <td>0.636023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24043</th>\n",
              "      <td>ffc0475ac3f403de</td>\n",
              "      <td>xclick</td>\n",
              "      <td>Truck</td>\n",
              "      <td>1</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>0.999375</td>\n",
              "      <td>0.245779</td>\n",
              "      <td>0.999062</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.826250</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>0.999375</td>\n",
              "      <td>0.999375</td>\n",
              "      <td>0.245779</td>\n",
              "      <td>0.814259</td>\n",
              "      <td>0.999062</td>\n",
              "      <td>0.999062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24045</th>\n",
              "      <td>ffc67982d4790275</td>\n",
              "      <td>xclick</td>\n",
              "      <td>Bus</td>\n",
              "      <td>1</td>\n",
              "      <td>0.456277</td>\n",
              "      <td>0.999134</td>\n",
              "      <td>0.392991</td>\n",
              "      <td>0.735920</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.568831</td>\n",
              "      <td>0.456277</td>\n",
              "      <td>0.669264</td>\n",
              "      <td>0.999134</td>\n",
              "      <td>0.392991</td>\n",
              "      <td>0.563204</td>\n",
              "      <td>0.735920</td>\n",
              "      <td>0.486859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24050</th>\n",
              "      <td>ffd1093b9f7d3e13</td>\n",
              "      <td>xclick</td>\n",
              "      <td>Bus</td>\n",
              "      <td>1</td>\n",
              "      <td>0.942500</td>\n",
              "      <td>0.999375</td>\n",
              "      <td>0.468105</td>\n",
              "      <td>0.768293</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.995625</td>\n",
              "      <td>0.942500</td>\n",
              "      <td>0.978750</td>\n",
              "      <td>0.999375</td>\n",
              "      <td>0.468105</td>\n",
              "      <td>0.608818</td>\n",
              "      <td>0.768293</td>\n",
              "      <td>0.583490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24059</th>\n",
              "      <td>fff376d20410e4c9</td>\n",
              "      <td>xclick</td>\n",
              "      <td>Bus</td>\n",
              "      <td>1</td>\n",
              "      <td>0.348125</td>\n",
              "      <td>0.701250</td>\n",
              "      <td>0.423333</td>\n",
              "      <td>0.744167</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.478750</td>\n",
              "      <td>0.493125</td>\n",
              "      <td>0.348125</td>\n",
              "      <td>0.701250</td>\n",
              "      <td>0.423333</td>\n",
              "      <td>0.744167</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.523333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24061</th>\n",
              "      <td>fffde5953a818927</td>\n",
              "      <td>xclick</td>\n",
              "      <td>Bus</td>\n",
              "      <td>1</td>\n",
              "      <td>0.613125</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.623333</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.613125</td>\n",
              "      <td>0.623333</td>\n",
              "      <td>0.760833</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.730000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8837 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                ImageID  Source LabelName  ...  XClick2Y  XClick3Y  XClick4Y\n",
              "2      00006bdb1eb5cd74  xclick     Truck  ...  0.398496  0.409774  0.295739\n",
              "8      0004d5a9dd44ab6a  xclick     Truck  ...  0.609495  0.934150  0.822358\n",
              "9      0004d5a9dd44ab6a  xclick     Truck  ...  0.294028  0.325421  0.390505\n",
              "15     0007eeeabf3c5e5c  xclick       Bus  ...  0.458889  0.647778  0.432222\n",
              "19     000924a411c24d25  xclick       Bus  ...  0.632270  0.702627  0.636023\n",
              "...                 ...     ...       ...  ...       ...       ...       ...\n",
              "24043  ffc0475ac3f403de  xclick     Truck  ...  0.814259  0.999062  0.999062\n",
              "24045  ffc67982d4790275  xclick       Bus  ...  0.563204  0.735920  0.486859\n",
              "24050  ffd1093b9f7d3e13  xclick       Bus  ...  0.608818  0.768293  0.583490\n",
              "24059  fff376d20410e4c9  xclick       Bus  ...  0.744167  0.537500  0.523333\n",
              "24061  fffde5953a818927  xclick       Bus  ...  0.760833  0.795833  0.730000\n",
              "\n",
              "[8837 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvBfcYYByS1m"
      },
      "source": [
        "**Define targets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKXdeY0oh2lO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dac7889-ff29-4b32-c96a-2a95422fe489"
      },
      "source": [
        "# this ensures whether the image ids are within unique imageid\n",
        "df = df[df['ImageID'].isin(df['ImageID'].unique().tolist())]\n",
        "# create target dictionary from unique labels\n",
        "label2target = {l:t+1 for t,l in enumerate(df_raw['LabelName'].unique())}\n",
        "# define additional target 'background' having id  = 0, used in SSD(-ve class)\n",
        "label2target['background'] = 0\n",
        "# define target2label dict\n",
        "target2label = {t:l for l,t in label2target.items()}\n",
        "\n",
        "num_classes = len(label2target)\n",
        "\n",
        "print(f'Dataset contains total {num_classes} classes, having below categories {target2label}')\n",
        "print(label2target)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset contains total 3 classes, having below categories {1: 'Bus', 2: 'Truck', 0: 'background'}\n",
            "{'Bus': 1, 'Truck': 2, 'background': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n31kHHQO0sKD"
      },
      "source": [
        "## **Data Pre-processing**\n",
        "\n",
        "Define functions for data pre-processing\n",
        "* In norm we normalize the individual channels by specifying individual means\n",
        "* 0.485, 0.456, 0.406 and 0.229, 0.224, 0.225 std for R,G,B channels respectively\n",
        "* normalize formula : value_norm = (value - mean)/std\n",
        "* denormalize(return to original raw value : \n",
        "val_dnorm = (value_norm/(1/std) - ((-mean/std)/(1/std)) = (value_norm*std - mean)\n",
        "* Generaly img tensor is fetched by torch as (H, W, C), but for torchvision operation and NN receives images of shape (C, H, W)\n",
        "* torch.permute() does this operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyyewDahxVAg"
      },
      "source": [
        "# normalize \n",
        "norm = transforms.Normalize(\n",
        "    mean = [0.485, 0.456, 0.406],\n",
        "    std = [0.229, 0.224, 0.225]\n",
        ")\n",
        "\n",
        "# de-normalization function\n",
        "de_norm = transforms.Normalize(\n",
        "    mean = [-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
        "    std = [1/0.229, 1/0.224, 1/0.255]\n",
        ")\n",
        "\n",
        "# define data pre-processing function\n",
        "def preprocess_img(img):\n",
        "  # reshape the img tensor\n",
        "  img = torch.tensor(img).permute(2,0,1)\n",
        "  img = normalize(img)\n",
        "  return img.to(device)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8jIc9OD6A6w"
      },
      "source": [
        "**Define torch dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juQF2Whc42-e"
      },
      "source": [
        "class OpenDataset(torch.utils.data.Dataset):\n",
        "  # set the resolutions of the dataset to 300\n",
        "  w,h = 300, 300\n",
        "  def __init__(self, df, img_dir = image_root):\n",
        "    self.img_dir = img_dir\n",
        "    self.files = glob.glob(self.img_dir+'/*')\n",
        "    self.df = df\n",
        "    self.img_infos = df.ImageID.unique()\n",
        "    # helps to log the info to the terminal or console\n",
        "    logger.info(f'{len(self.img_infos)} items loaded!')\n",
        "  def __getitem__(self, ix):\n",
        "    # load images and masks\n",
        "    # loads image ids from infos fetched from df\n",
        "    img_id = self.img_infos[ix]\n",
        "    # find path from glob paths corresponding to img ids\n",
        "    img_path = find(img_id, self.files)\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    # convert images to np.array with resized shape using Bicubic interpolation\n",
        "    img = np.array(img.resize((self.w, self.h), \n",
        "                   resample = Image.BICUBIC))/255.\n",
        "    # now fetch row info correponding to te image id\n",
        "    data = self.df[self.df['ImageID'] == img_id]\n",
        "    # fetch list of labels correwsponding to that image id bcz of multi-object\n",
        "    labels = data['LabelName'].values.tolist()\n",
        "    # fetch the bbox regression infos\n",
        "    data = data[['XMin', 'YMin', 'XMax', 'YMax']].values\n",
        "    # multiply width to normalized xmin and xmax col\n",
        "    data[:, [0,2]] *= self.w\n",
        "    # multiply height to normalized ymin and ymax col\n",
        "    data[:, [1,3]] *= self.h\n",
        "    # define box parameter\n",
        "    boxes = data.astype(np.uint32).tolist()\n",
        "    # convert to abosolute coordinate\n",
        "    img = img.astype(np.float32)\n",
        "    return img, boxes, labels\n",
        "  # collate fn helps to create batches\n",
        "  def collate_fn(self, batch):\n",
        "    images, boxes, labels = [], [], []\n",
        "    # batch contain batch of data\n",
        "    # each sample corresponding to batch contain img array, label, bbox\n",
        "    # each sample is called here as item\n",
        "    for item in batch:\n",
        "      img, img_boxes, img_labels = item\n",
        "      # that None index adds 1 dimension at the start of the shape\n",
        "      #(3,300,300) to (1, 3, 300, 300)\n",
        "      # else the batch shape will be like (4*3,300,300)\n",
        "      img = preprocess_img(img)[None]\n",
        "      images.append(img)\n",
        "      # we normalize every box parameters to 300\n",
        "      # as resize img dimension is 300\n",
        "      boxes.append(torch.tensor(img_boxes).float().to(device)/300.)\n",
        "      # pic labels class from labelstotarget list\n",
        "      labels.append(torch.tensor([label2target[c] for c in img_labels]).long().to(device))\n",
        "    # convert images list to torch tensor and load to device\n",
        "    images = torch.cat(images).to(device)  \n",
        "    return images, boxes, labels\n",
        "    # in torch the dataset fn makes the __len__ callable with the object of dataset class\n",
        "    # also the getitem is callable with object\n",
        "    # so no need to call the getitem seperately after declaring the dataset object\n",
        "  def __len__(self):\n",
        "    return len(self.img_infos)\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmDq__tJQAKZ"
      },
      "source": [
        "#### **Define train, validation, test split**\n",
        "\n",
        "* We used split ratio of 0.1 for test data\n",
        "* Splitted the image ids, and based on that fetched the coresponding info from dataframe for train adn test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXZoxEbccIak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3044c520-316e-4cbd-cd3f-4e9e2eff0b0f"
      },
      "source": [
        "# fetch train and valid ids\n",
        "train_ids, valid_ids = train_test_split(df.ImageID.unique(), test_size = 0.2, random_state = 99)\n",
        "# fetch valid and test\n",
        "valid_ids, test_ids = train_test_split(df.ImageID.unique(), test_size = 0.5, random_state = 48)\n",
        "\n",
        "# fetch info from df\n",
        "train_df, valid_df, test_df = df[df['ImageID'].isin(train_ids)],df[df['ImageID'].isin(valid_ids)],df[df['ImageID'].isin(test_ids)]\n",
        "\n",
        "print('Train, valid, Test info-')\n",
        "print(f'Train- {train_df.shape}')\n",
        "print(f'Valid- {valid_df.shape}')\n",
        "print(f'Test- {test_df.shape}')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train, valid, Test info-\n",
            "Train- (19207, 21)\n",
            "Valid- (12008, 21)\n",
            "Test- (12054, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFYvaMZ1R8Jx"
      },
      "source": [
        "#### **Obtain the Dataset and Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjIFPSGEgmY3"
      },
      "source": [
        "batch_size = 32"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of_UE2lTR4oy",
        "outputId": "4e081bc1-153a-4401-9bec-11ceca1ee2d8"
      },
      "source": [
        "# obtain train, valid, test dataset\n",
        "train_ds = OpenDataset(train_df)\n",
        "valid_ds = OpenDataset(valid_df)\n",
        "test_ds = OpenDataset(test_df)\n",
        "\n",
        "# dataloader helps to load the dataset in the device/gpu here\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, \n",
        "                      # we pass the fn name in the argument so as to print that ewhile dataloader is in use\n",
        "                      # else it would ask for \n",
        "                      collate_fn = train_ds.collate_fn,# helps to process the batch items inside the loader\n",
        "                      drop_last = True # drops the last incomplete batch if is set to true\n",
        "                      )\n",
        "\n",
        "valid_dl = DataLoader(valid_ds, batch_size=batch_size, \n",
        "                      collate_fn = valid_ds.collate_fn,# helps to process the batch items inside the loader\n",
        "                      drop_last = True # drops the last incomplete batch if is set to true\n",
        "                      )\n",
        "\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, \n",
        "                      collate_fn = test_ds.collate_fn,# helps to process the batch items inside the loader\n",
        "                      drop_last = True # drops the last incomplete batch if is set to true\n",
        "                      )"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-02 21:17:12.638 | INFO     | __main__:__init__:10 - 12180 items loaded!\n",
            "2021-11-02 21:17:12.685 | INFO     | __main__:__init__:10 - 7612 items loaded!\n",
            "2021-11-02 21:17:12.731 | INFO     | __main__:__init__:10 - 7613 items loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdAjHY_IIhif"
      },
      "source": [
        "## **Define SSD300 Model requisities**\n",
        "\n",
        "Import SSD300 model, Multibox loss, Detection script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-7wOivrSLNq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a1516d-3602-4324-a9c3-cc770cbdf60c"
      },
      "source": [
        "# navigate to ssdutils path\n",
        "%cd /content/ssd-utils\n",
        "\n",
        "# import ssd dependencies\n",
        "from model import SSD300, MultiBoxLoss\n",
        "from detect import *"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ssd-utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYdKJxV7KcFp"
      },
      "source": [
        "**Initialize Model and Loss functions objects**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGZ44VP9KbgZ",
        "outputId": "581c17bf-6361-45d0-fe23-2994176daa86"
      },
      "source": [
        "# model object\n",
        "model = SSD300(num_classes, device)\n",
        "\n",
        "# model loss criterion\n",
        "# model.priors_cxcy returns the loss predicted values\n",
        "criterion = MultiBoxLoss(priors_cxcy= model.priors_cxcy, device = device)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded base model.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLmxUyVcKRC2"
      },
      "source": [
        "## **Model Training**\n",
        "\n",
        "Define model training functions for custom data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcSzW85TL5en"
      },
      "source": [
        "**Define Training Metadata**\n",
        "\n",
        "* weight decay is related to L2 regularization(lambda constant for L2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9Z9VpG-KEeP"
      },
      "source": [
        "# epochs\n",
        "n_epochs = 10\n",
        "\n",
        "# define optimizer\n",
        "# model.parameters() methods returns the model parameters\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-04, weight_decay= 1e-05)\n",
        "\n",
        "# define training log object\n",
        "log = Report(n_epochs=n_epochs)\n",
        "logs_to_print = 5"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_T6Y6W1Ok-n"
      },
      "source": [
        "#### **Define Training methods**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdobcVSCQ-63"
      },
      "source": [
        "# define train methods\n",
        "def train_batch(inputs, model, criterion, optimizer):\n",
        "  # open model in train mode so tha the dropout and all the training aspects are active\n",
        "  model.train()\n",
        "  n = len(train_dl)\n",
        "  images, boxes, labels = inputs\n",
        "  # predictions regression parameters, labels\n",
        "  _regr, _clss = model(images)\n",
        "  # evaluate loss for both boxes and labels\n",
        "  loss = criterion(_regr, _clss, boxes, labels)\n",
        "  # make the gradients variables to zero, so that it can obtain gradients based on current loss\n",
        "  optimizer.zero_grad()\n",
        "  # backprop to obtain the gradients\n",
        "  loss.backward()\n",
        "  # update the parameters based using the optimizer\n",
        "  optimizer.step()\n",
        "  return loss\n",
        "\n",
        "## validation method\n",
        "# this decorator initializes that the method no grad calculation will be done using torch utilities while computing val_loss\n",
        "#@torch.no_grad()\n",
        "def val_batch(inputs, model, criterion, optimizer):\n",
        "  # update model parameters based on validation data too\n",
        "  model.train()\n",
        "  n = len(valid_dl)\n",
        "  images, boxes, labels = inputs\n",
        "  _regr, _label = model(images)\n",
        "  loss = criterion(_regr, _label, _boxes, labels)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkIskAkmX_Ie"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rglzk33yNk5o",
        "outputId": "4fd71a9a-fd8a-450e-90c8-f90c09da45ed"
      },
      "source": [
        "# train and validation loop\n",
        "for epoch in range(n_epochs):\n",
        "  # when we call train loader that will fetch data using train dataset\n",
        "  _n = len(train_dl)\n",
        "  for ix, inputs in enumerate(train_dl):\n",
        "    loss = train_batch(inputs, model, criterion, optimizer)\n",
        "    # calculate training step in epoch or position of training\n",
        "    pos = (epoch + (ix+1)/_n)\n",
        "    log.record(pos, trn_loss = loss.item(), end = '\\r')\n",
        "\n",
        "  # validation step\n",
        "  for ix, inputs in enumerate(valid_dl):\n",
        "    val_loss = val(inputs, model, criterion, optimizer)\n",
        "    pos = (epoch + (ix+1)/_n)\n",
        "    log.record(pos, val_loss = val_loss.item(), end = '\\r')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0.053\ttrn_loss: 5.478\t(232.95s - 44027.65s remaining)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abkhIsNAYXf1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}